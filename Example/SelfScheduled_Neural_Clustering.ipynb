{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vup_gmBK5Uv4"
      ],
      "mount_file_id": "17k-4BD1MPyvLFNGgUcm9_l3wRRZ9cMgw",
      "authorship_tag": "ABX9TyONCeTU9zL68qcQsPwm3QJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabrizioC95/SelfScheduled_Neural_Clustering/blob/main/SelfScheduled_Neural_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This file contains an example of running the self-scheduled network.\n",
        "\n",
        "*   Libraries are installed\n",
        "*   Dependencies are defined\n",
        "*   Example of using the network\n",
        "*   Code so you can run on your own data"
      ],
      "metadata": {
        "id": "P7hA26yBKQ-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and run libraries"
      ],
      "metadata": {
        "id": "j4H6nKhHKG1T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xUS4ulre5Jpj"
      },
      "outputs": [],
      "source": [
        "#----- Install the following libraries\n",
        "!pip install torch --quiet\n",
        "#!pip install sklearn --quiet\n",
        "\n",
        "#-- General Libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "#-- Libraries for Neural Network\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#-- Shallow Clustering Methods (for pre-training)\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#-- Datasets and Dataloder\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Dependencies: **Simply run this code block (click the ▶ button next to 'cell hidden')**\n",
        "\n",
        "1.   Neural Architecture\n",
        "2.   Utils (Dataloader, Pytorch seed generator, Inference function)\n",
        "3.   The various trainers that are needed\n",
        "4.   Function orchestrating everything\n",
        "\n",
        "# ---"
      ],
      "metadata": {
        "id": "vup_gmBK5Uv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "#-----------------------------Architecture--------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-----------------------------\n",
        "#----- Single Autoencoder\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, data_dim, hidden_dim, batch_normalize=False, dropout=[False, 0.2]):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        # Store parameters\n",
        "        self.data_dim = data_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_normalize = batch_normalize\n",
        "        self.dropout = dropout[0]  #True/False\n",
        "        self.dropout_p = dropout[1]  #Dropout probability\n",
        "\n",
        "        #-- Encoder Layers\n",
        "        encoder_layers = []\n",
        "        input_size = data_dim\n",
        "\n",
        "        for idx, h_dim in enumerate(hidden_dim[:-1]):\n",
        "            layer = nn.Linear(input_size, h_dim)\n",
        "            nn.init.xavier_uniform_(layer.weight)\n",
        "            encoder_layers.append(layer)\n",
        "\n",
        "            if batch_normalize:\n",
        "                encoder_layers.append(nn.BatchNorm1d(h_dim))\n",
        "\n",
        "            encoder_layers.append(nn.ELU())\n",
        "\n",
        "            #-- Dropout\n",
        "            if self.dropout:\n",
        "                encoder_layers.append(nn.Dropout(p=self.dropout_p))\n",
        "\n",
        "            input_size = h_dim\n",
        "\n",
        "        #--- Embedding Layer\n",
        "        self.embedding_layer = nn.Linear(hidden_dim[-2], hidden_dim[-1])\n",
        "        nn.init.xavier_uniform_(self.embedding_layer.weight)\n",
        "\n",
        "        #--- Decoder Layers\n",
        "        decoder_layers = []\n",
        "        input_size = hidden_dim[-1]\n",
        "        for idx, h_dim in enumerate(reversed(hidden_dim[:-1])):\n",
        "            layer = nn.Linear(input_size, h_dim)\n",
        "            nn.init.xavier_uniform_(layer.weight)\n",
        "            decoder_layers.append(layer)\n",
        "\n",
        "            if batch_normalize:\n",
        "                decoder_layers.append(nn.BatchNorm1d(h_dim))\n",
        "\n",
        "            decoder_layers.append(nn.ELU())\n",
        "\n",
        "            #-- Dropout\n",
        "            if self.dropout:\n",
        "                decoder_layers.append(nn.Dropout(p=self.dropout_p))\n",
        "\n",
        "            input_size = h_dim\n",
        "\n",
        "        #--- Final output layer\n",
        "        self.final_layer = nn.Sequential(\n",
        "            nn.Linear(input_size, data_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        nn.init.xavier_uniform_(self.final_layer[0].weight)\n",
        "\n",
        "        #-- Assign encoder and decoder as sequential modules\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        embedding = self.embedding_layer(encoded)\n",
        "        decoded = self.decoder(embedding)\n",
        "        output = self.final_layer(decoded)\n",
        "\n",
        "        return embedding, output\n",
        "\n",
        "#-----------------------------\n",
        "#----- Stack of autoencoders\n",
        "class KAutoEncoders(nn.Module):\n",
        "    def __init__(self, k, data_dim, hidden_dim, batch_normalize=False, dropout=[False, 0.0]):\n",
        "        super(KAutoEncoders, self).__init__()\n",
        "        self.k = k\n",
        "        self.data_dim = data_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Initialize k autoencoders with feature selection\n",
        "        self.autoencoders = nn.ModuleList(\n",
        "            [AutoEncoder(data_dim,\n",
        "                         hidden_dim,\n",
        "                         batch_normalize,\n",
        "                         dropout=self.dropout)\n",
        "             for _ in range(k)])\n",
        "\n",
        "    #--- Forward pass\n",
        "    def forward(self, x):\n",
        "        reconstructions = []\n",
        "        embeddings = []\n",
        "\n",
        "        for autoencoder in self.autoencoders:\n",
        "            embedding, reconstruction = autoencoder(x)\n",
        "            embeddings.append(embedding)\n",
        "            reconstructions.append(reconstruction)\n",
        "\n",
        "        reconstructions = torch.stack(reconstructions, dim=1)  # Shape: (batch_size, k, data_dim)\n",
        "        embeddings = torch.stack(embeddings, dim=1)  # Shape: (batch_size, k, embedding_dim)\n",
        "\n",
        "        return embeddings, reconstructions\n",
        "\n",
        "\n",
        "#-----------------------------\n",
        "#----- Clustering Network\n",
        "class MixtureAssignmentNetwork(nn.Module):\n",
        "    def __init__(self, k, data_dim, cluster_hidden_sizes, batch_normalize=False):\n",
        "        super(MixtureAssignmentNetwork, self).__init__()\n",
        "\n",
        "        #-- Define needed layers\n",
        "        layers = []\n",
        "        in_dim = data_dim\n",
        "\n",
        "        #-- Hidden Layers\n",
        "        for hidden_size in cluster_hidden_sizes:\n",
        "            linear_layer = nn.Linear(in_dim, hidden_size)\n",
        "            nn.init.xavier_uniform_(linear_layer.weight)\n",
        "            layers.append(linear_layer)\n",
        "\n",
        "            if batch_normalize:\n",
        "                layers.append(nn.BatchNorm1d(hidden_size))\n",
        "\n",
        "            layers.append(nn.ELU())\n",
        "            in_dim = hidden_size\n",
        "\n",
        "        #-- Output layer\n",
        "        output_layer = nn.Linear(in_dim, k)\n",
        "        nn.init.xavier_uniform_(output_layer.weight)\n",
        "        layers.append(output_layer)\n",
        "        layers.append(nn.Softmax(dim=1))\n",
        "\n",
        "        #-- Make sequential\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "#-----------------------------\n",
        "#----- Wrapper to call it all\n",
        "class ClusteringAutoEncoder(nn.Module):\n",
        "    def __init__(self, k, data_dim, hidden_dim, cluster_hidden_sizes, batch_normalize=False, cluster_batch_normalize=False, dropout=[False, 0.0]):\n",
        "        super(ClusteringAutoEncoder, self).__init__()\n",
        "\n",
        "        #--- K AutoEncoders\n",
        "        self.k_autoencoders = KAutoEncoders(\n",
        "            k=k,\n",
        "            data_dim=data_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            batch_normalize=batch_normalize,\n",
        "            dropout=dropout  # Pass dropout as [bool, float]\n",
        "        )\n",
        "\n",
        "        #--- Classification Network\n",
        "        self.cluster_net = MixtureAssignmentNetwork(\n",
        "            k=k,\n",
        "            data_dim=data_dim,\n",
        "            cluster_hidden_sizes=cluster_hidden_sizes,\n",
        "            batch_normalize=cluster_batch_normalize\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #--- Pass through K autoencoders\n",
        "        embeddings, reconstructions = self.k_autoencoders(x)\n",
        "\n",
        "        #--- Forward pass through classification network\n",
        "        cluster_probs = self.cluster_net(x)\n",
        "\n",
        "        return embeddings, reconstructions, cluster_probs\n",
        "        #Shape: (batch_size, k, embedding_dim)\n",
        "        #Shape: (batch_size, k, data_dim)\n",
        "        #Shape: (batch_size, num_clusters)\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "#---------------------------------Utils-----------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "def load_data(df, categorical_cols=None, numerical_cols=None, k=None, batch_size=None, generator=None):\n",
        "  #-------------------------------#\n",
        "  #------ Initialize encoders ---#\n",
        "  #------------------------------#\n",
        "  scaler = MinMaxScaler()\n",
        "  categorical_cols = categorical_cols if categorical_cols is not None else []\n",
        "  numerical_cols = numerical_cols if numerical_cols is not None else []\n",
        "\n",
        "  #--------------------------\n",
        "  #--- General daloader -----\n",
        "  #--------------------------\n",
        "  class NormalDataloader(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "      self.X = torch.tensor(dataframe.to_numpy(), dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return self.X[idx], idx\n",
        "  #----------------------------\n",
        "  #--------- Warning Messages\n",
        "  #---------\n",
        "\n",
        "  #- Check that the columns passed are list types\n",
        "  if not isinstance(categorical_cols, list) or not isinstance(numerical_cols, list):\n",
        "    raise ValueError(\"Both 'categorical_cols' and 'numerical_cols' must be a 'list' object type.\")\n",
        "\n",
        "  #- Check that at least one of the columns is provided\n",
        "  if not categorical_cols and not numerical_cols:\n",
        "    raise ValueError(\"You need to define 'categorical_cols' and/or 'numerical_cols' \")\n",
        "\n",
        "  #- Check that the columns exist\n",
        "  missing_cols = [col for col in (numerical_cols + categorical_cols) if col not in df.columns]\n",
        "  if missing_cols:\n",
        "    raise ValueError(f\"The following columns not found in the dataframe: {missing_cols}\")\n",
        "\n",
        "  #- Check that \"k\" is provided\n",
        "  if not isinstance(k, int) or k <= 0:\n",
        "    raise ValueError(\"Number of clusters ('k = __') must be provided. E.g., how many should there be?\")\n",
        "\n",
        "  #- Check that there are no missing values\n",
        "  if df.isnull().values.any():\n",
        "    raise ValueError(\"Data contains missing values. Please handle NaNs before using this function\")\n",
        "\n",
        "\n",
        "  #----------------------------\n",
        "  #--------- Encoding categorical variables\n",
        "  #---------\n",
        "  if categorical_cols:\n",
        "    df = pd.get_dummies(df, columns=categorical_cols, dtype=float)\n",
        "\n",
        "  #----------------------------\n",
        "  #--------- Encoding numerical variables\n",
        "  #---------\n",
        "  if numerical_cols:\n",
        "    df[numerical_cols] = df[numerical_cols].astype(float)\n",
        "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "\n",
        "  #----------------------------\n",
        "  #--------- Extras\n",
        "  shape = df.shape[1]\n",
        "  dataset = NormalDataloader(df)\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, generator=generator)\n",
        "\n",
        "  return dataset, dataloader, k, shape, df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------------------\n",
        "#------------- Seed Generator ----------------\n",
        "#--------------------------------------------\n",
        "#-- We require a seed generator for numpy operations and pytorch operations\n",
        "def reset_seed(seed):\n",
        "  torch.manual_seed(seed) #- For Pytorch generator\n",
        "  np.random.seed(seed) #- For custom operators, according to PyTorch docs\n",
        "  random.seed(seed) #- For python Operations\n",
        "\n",
        "  #--- CUDA Seed\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "  #--- Fixing dataloader shuffle\n",
        "  generator = torch.Generator()\n",
        "  generator.manual_seed(seed)\n",
        "\n",
        "  return generator\n",
        "\n",
        "\n",
        "#---------------------------------------------\n",
        "#------------- Inference ----------------\n",
        "#--------------------------------------------\n",
        "def run_inference(model, dataloader, dataset, device, k):\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "\n",
        "\n",
        " #-- Training\n",
        "  with torch.no_grad():\n",
        "    for batch, indices in dataloader:\n",
        "      batch = batch.to(device)\n",
        "\n",
        "      #- Forward pass\n",
        "      _, _, probs = model(batch)\n",
        "\n",
        "      #- Cluster assignment\n",
        "      best_autoencoder = torch.argmax(probs, dim=1).cpu().numpy()\n",
        "      indices = indices.cpu().numpy()\n",
        "\n",
        "      #- Store results\n",
        "      for idx, cluster in zip(indices, best_autoencoder):\n",
        "        predictions.append((idx, cluster))\n",
        "\n",
        "  #-- Save prediction as dataframe\n",
        "  results = pd.DataFrame(predictions, columns=['Index', 'Cluster'])\n",
        "  return results\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "#-------------------------------Trainers----------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "#-----------------------------------------\n",
        "#----- Pre-training Classification Network\n",
        "def shallow_pt_first(k, input_features, targets=None, model='kmeans', generator=None, random_seed=None):\n",
        "    #-- Convert to NumPy\n",
        "    if isinstance(input_features, pd.DataFrame):\n",
        "        input_features = input_features.to_numpy()\n",
        "\n",
        "    if isinstance(input_features, torch.Tensor):\n",
        "        input_features = input_features.numpy()\n",
        "\n",
        "    #--- Use pytorch seed generator if provided\n",
        "    #--- If not this uses the default RNG generator\n",
        "\n",
        "    #- Raise error if both arguments are passed\n",
        "    if generator is not None and random_seed is not None:\n",
        "      raise ValueError(\"Both 'generator' and 'random_seed' arguments cannot be provided at the same time\")\n",
        "\n",
        "    if generator is not None:\n",
        "      random_state = generator.initial_seed()\n",
        "\n",
        "    elif random_seed is not None:\n",
        "      random_state = random_seed\n",
        "\n",
        "    else:\n",
        "      #- Default to regular, unfixed, RNG if neither arguments are provided\n",
        "      random_state = random_seed\n",
        "\n",
        "    #-- Conduct K-means clustering\n",
        "    if model == 'kmeans':\n",
        "        p_kmeans = KMeans(n_clusters=k, random_state=random_state)\n",
        "        pseudo_labels = p_kmeans.fit_predict(input_features)\n",
        "\n",
        "    #-- Create aligned dataset with pseudo-labels\n",
        "    feature_columns = [f\"feature_{i}\" for i in range(input_features.shape[1])]\n",
        "    aligned_df = pd.DataFrame(input_features, columns=feature_columns)\n",
        "    aligned_df['pseudo_labels'] = pseudo_labels\n",
        "\n",
        "    return aligned_df\n",
        "\n",
        "#-----------------------------------------\n",
        "#----- Pre-training Classification Network\n",
        "#- Uses the pseudo-labels to train the clustering network through a classification task.\n",
        "def pretrain_mixture_assignment_network(k, pseudo_data, data_dim, cluster_hidden_sizes,\n",
        "                                        batch_normalize=True, pt_num_epochs=10,\n",
        "                                        pt_batch_size=64, pre_lr=0.001, weight_decay=.001, generator=None, device=None):\n",
        "  class MixtureDataLoader(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.features = dataframe.drop(columns=['pseudo_labels']).values\n",
        "        self.pseudo_labels = dataframe['pseudo_labels'].values\n",
        "\n",
        "        self.X = torch.tensor(self.features, dtype=torch.float32)\n",
        "        self.y = torch.tensor(self.pseudo_labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Return the data point, index, and pseudo-label for the given index.\"\"\"\n",
        "        return self.X[idx], idx, self.y[idx]\n",
        "\n",
        "    #--- Initialize classification network\n",
        "  mixture_assignment_net = MixtureAssignmentNetwork(\n",
        "      k=k,\n",
        "      data_dim=data_dim,\n",
        "      cluster_hidden_sizes=cluster_hidden_sizes,\n",
        "      batch_normalize=batch_normalize\n",
        "  ).to(device)\n",
        "\n",
        "  #--- Initialize dataloader\n",
        "  dataset = MixtureDataLoader(pseudo_data)\n",
        "  dataloader = DataLoader(dataset, batch_size=pt_batch_size, shuffle=True, generator=generator)\n",
        "\n",
        "  #--- Define loss\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(mixture_assignment_net.parameters(), lr=pre_lr, weight_decay=weight_decay)\n",
        "\n",
        "  #--- Training loop\n",
        "  mixture_assignment_net.train()\n",
        "\n",
        "  for epoch in range(pt_num_epochs):\n",
        "\n",
        "    for batch_data, _, pseudo_labels in dataloader:\n",
        "      optimizer.zero_grad()\n",
        "      batch_data, pseudo_labels = batch_data.to(device), pseudo_labels.to(device)\n",
        "\n",
        "      #--- Forward pass\n",
        "      outputs = mixture_assignment_net(batch_data)\n",
        "\n",
        "      #--- Loss\n",
        "      loss = criterion(outputs, pseudo_labels)\n",
        "\n",
        "      #--- Backprop\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  return mixture_assignment_net\n",
        "\n",
        "\n",
        "#-----------------------------------------\n",
        "#----- General Trainer\n",
        "def samplewise_trainer(model, dataloader, dataset, optimizer, num_epochs, alpha, beta, k, device, schedule='batch'):\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for batch, indices in dataloader:\n",
        "      batch=batch.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #-- Forward pass\n",
        "      embeddings, reconstructions, probs = model(batch)\n",
        "\n",
        "      #-- Weighted Reconstruction Loss\n",
        "      batch_expanded = batch.unsqueeze(1)\n",
        "      diff = batch_expanded - reconstructions\n",
        "      l2_norm = torch.sum(diff ** 2, dim=-1)\n",
        "      weighted_errors = probs * l2_norm\n",
        "      ae_losses = torch.sum(weighted_errors, dim=1)\n",
        "\n",
        "      #-- Sample-Wise Entropy\n",
        "      sample_entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1)\n",
        "\n",
        "      #-- Batch-Wise Entropy\n",
        "      avg_probs = probs.mean(dim=0)\n",
        "      batch_entropy = -torch.sum(avg_probs * torch.log(avg_probs + 1e-8))\n",
        "\n",
        "      #-- Loss Function\n",
        "      total_loss = (torch.sum(ae_losses + alpha * sample_entropy) / batch.size(0)) - beta * batch_entropy\n",
        "\n",
        "      #-- Backprop\n",
        "      total_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      #-- Batch Scheduled Training\n",
        "      if schedule == 'batch':\n",
        "        with torch.no_grad():\n",
        "          alpha = 1\n",
        "          samplewise_term = (torch.sum(ae_losses + alpha * sample_entropy) / batch.size(0))\n",
        "          batch_entr_magnitude = -torch.sum(avg_probs * torch.log(avg_probs + 1e-8))\n",
        "          beta = samplewise_term / (batch_entr_magnitude + 1e-8)\n",
        "\n",
        "    #-- Epoch Scheduled Training\n",
        "    if schedule == 'epoch':\n",
        "      with torch.no_grad():\n",
        "        alpha = 1\n",
        "        samplewise_term = (torch.sum(ae_losses + alpha * sample_entropy) / batch.size(0))\n",
        "        batch_entr_magnitude = -torch.sum(avg_probs * torch.log(avg_probs + 1e-8))\n",
        "        beta = samplewise_term / (batch_entr_magnitude + 1e-8)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------\n",
        "#----- General Training Function\n",
        "def train_model(data,\n",
        "                k,\n",
        "                categorical_cols,\n",
        "                numerical_cols,\n",
        "                batch_size,\n",
        "                hidden_dim=[128,64,32],\n",
        "                cluster_hidden_sizes=[64,32],\n",
        "                num_epochs=100,\n",
        "                pt_num_epochs=10,\n",
        "                lr =.001,\n",
        "                seed=10):\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Device: Using {device} for training\")\n",
        "\n",
        "  #--- Seed generator\n",
        "  generator = reset_seed(seed)\n",
        "\n",
        "  #--- Initialize dataloader\n",
        "  print(\"Initializing dataloader..\")\n",
        "  dataset, dataloader, k, data_dim, df = load_data(\n",
        "      df=data,\n",
        "      categorical_cols=categorical_cols,\n",
        "      numerical_cols=numerical_cols,\n",
        "      k=k,\n",
        "      batch_size=batch_size)\n",
        "\n",
        "  #--- Pre-training\n",
        "  pseudo_data = shallow_pt_first(k=k, input_features=df, model='kmeans', generator=generator)\n",
        "\n",
        "  pretrained_man = pretrain_mixture_assignment_network(\n",
        "      k=k,\n",
        "      pseudo_data=pseudo_data,\n",
        "      data_dim=data_dim,\n",
        "      cluster_hidden_sizes=cluster_hidden_sizes,\n",
        "      batch_normalize=True,\n",
        "      pt_num_epochs=pt_num_epochs,\n",
        "      pt_batch_size=batch_size,\n",
        "      pre_lr=0.001,\n",
        "      weight_decay=0.001,\n",
        "      generator=generator,\n",
        "      device=device)\n",
        "\n",
        "  #--- Initialize Model\n",
        "  model = ClusteringAutoEncoder(\n",
        "      k=k,\n",
        "      data_dim=data_dim,\n",
        "      hidden_dim=hidden_dim,\n",
        "      cluster_hidden_sizes=cluster_hidden_sizes,\n",
        "      batch_normalize=True,\n",
        "      cluster_batch_normalize=True,\n",
        "      dropout=[False, 0.0]).to(device)\n",
        "\n",
        "\n",
        "  #--- Load Pre-Trained Mixture Assignment Network Weights\n",
        "  model.cluster_net.load_state_dict(pretrained_man.state_dict())\n",
        "\n",
        "  #--- Model optimizer\n",
        "  optimizer=torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  #--- Train model using appropriate training schedule\n",
        "  print(\"Training Network..\")\n",
        "  trained_model = samplewise_trainer(\n",
        "          model=model,\n",
        "          dataloader=dataloader,\n",
        "          dataset=dataset,\n",
        "          optimizer=optimizer,\n",
        "          num_epochs=num_epochs,\n",
        "          alpha=5,\n",
        "          beta=5,\n",
        "          k=k,\n",
        "          device=device,\n",
        "          schedule=\"batch\")\n",
        "\n",
        "  #--- Run inference\n",
        "  print(\"Running inference\")\n",
        "  inference_df = run_inference(\n",
        "      model=trained_model,\n",
        "      dataloader=dataloader,\n",
        "      dataset=dataset,\n",
        "      device=device,\n",
        "      k=k)\n",
        "\n",
        "  #--- Align predictions with original dataset\n",
        "  results_df = df.copy()\n",
        "  results_df['Cluster'] = results_df.index.map(inference_df.set_index('Index')['Cluster'])\n",
        "\n",
        "  return results_df"
      ],
      "metadata": {
        "id": "aE8p6zOB5T_Q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#------------------------------------------------------------------------------\n",
        "# **Example of using the network. This code does the following:**\n",
        "\n",
        "### 1. Generate a dataset to play with  \n",
        "\n",
        "### 2. List out columns by variable type (continuous, categorical)  \n",
        "    - List containing the name of the columns with continuous values is defined\n",
        "    - List containing the name of the columns with categorical values is defined  \n",
        "\n",
        "### 3. Set settings for training:  \n",
        "    - data = your cleaned dataset (cannot have missing values)  \n",
        "    - k = number of clusters  \n",
        "    - categorical_cols = The list with the names of the categorical columns  \n",
        "    - numerical_cols = The list with the names of the continuous columns\n",
        "    - batch_size = Defines how many data points are fed into the network per training step\n",
        "\n",
        "### 4. The resulting dataset contains the **TRANSFORMED** variables, and a new column \"Clusters\" containing the cluster assignment for each person.\n",
        "\n",
        "\n",
        "### **NOTE**: Other settings exist but these are the bare minimum ones  \n",
        "# ---\n",
        "\n"
      ],
      "metadata": {
        "id": "wmyFcMrGzFL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------\n",
        "#---------- 1.Generate a dataset ---------\n",
        "#-----------------------------------------\n",
        "n_clusters = 3\n",
        "cluster_samples = 500 // n_clusters\n",
        "\n",
        "df_store = []\n",
        "\n",
        "for cluster_id in range(n_clusters):\n",
        "    categorical_variable1 = np.random.choice(['A', 'B', 'C'], size=cluster_samples)\n",
        "    categorical_variable2 = np.random.choice(['X', 'Y', 'Z'], size=cluster_samples)\n",
        "\n",
        "    num1 = cluster_id * 50 + np.random.normal(scale=5, size=cluster_samples)\n",
        "    num2 = cluster_id * 20 + np.random.normal(scale=3, size=cluster_samples)\n",
        "\n",
        "    cluster_df = pd.DataFrame({'category1': categorical_variable1, 'category2': categorical_variable2, 'num1': num1, 'num2': num2})\n",
        "    df_store.append(cluster_df)\n",
        "\n",
        "df = pd.concat(df_store, ignore_index=True)\n",
        "\n",
        "#-----------------------------------------\n",
        "# 2. List out Columns by variable\n",
        "#     (numerical, categorical)\n",
        "#-----------------------------------------\n",
        "numerical_columns = ['num1', 'num2']\n",
        "categorical_columns = ['category1', 'category2']\n",
        "\n",
        "\n",
        "#-----------------------------------------\n",
        "#---------- 3. Train the Model -----------\n",
        "#-----------------------------------------\n",
        "results_df = train_model(\n",
        "    data=df,\n",
        "    k=3,\n",
        "    categorical_cols=categorical_columns,\n",
        "    numerical_cols=numerical_columns,\n",
        "    batch_size=100)\n",
        "\n",
        "\n",
        "#-----------------------------------------\n",
        "#--------------- Results -----------------\n",
        "#-----------------------------------------\n",
        "#- The resulting dataframe contains a new column \"Cluster\" with the cluster assignment\n",
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "collapsed": true,
        "id": "bMNCzl1h4sOW",
        "outputId": "9517d0f1-07cb-4dd2-c110-491d891054bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: Using cpu for training\n",
            "Initializing dataloader..\n",
            "Training Network..\n",
            "Running inference\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         num1      num2  category1_A  category1_B  category1_C  category2_X  \\\n",
              "0    0.139401  0.120370          0.0          1.0          0.0          0.0   \n",
              "1    0.092131  0.181113          0.0          1.0          0.0          0.0   \n",
              "2    0.103859  0.186419          1.0          0.0          0.0          1.0   \n",
              "3    0.100719  0.098470          1.0          0.0          0.0          0.0   \n",
              "4    0.104481  0.121441          0.0          1.0          0.0          1.0   \n",
              "..        ...       ...          ...          ...          ...          ...   \n",
              "493  0.878775  0.886209          1.0          0.0          0.0          0.0   \n",
              "494  0.892436  0.879508          1.0          0.0          0.0          0.0   \n",
              "495  0.926543  0.809942          0.0          0.0          1.0          0.0   \n",
              "496  0.973000  0.751529          0.0          0.0          1.0          1.0   \n",
              "497  0.920492  0.887769          0.0          1.0          0.0          0.0   \n",
              "\n",
              "     category2_Y  category2_Z  Cluster  \n",
              "0            1.0          0.0        1  \n",
              "1            0.0          1.0        1  \n",
              "2            0.0          0.0        2  \n",
              "3            1.0          0.0        2  \n",
              "4            0.0          0.0        1  \n",
              "..           ...          ...      ...  \n",
              "493          0.0          1.0        2  \n",
              "494          0.0          1.0        2  \n",
              "495          0.0          1.0        0  \n",
              "496          0.0          0.0        0  \n",
              "497          0.0          1.0        1  \n",
              "\n",
              "[498 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1894f2f-66fc-45f4-ace2-19c259825b59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num1</th>\n",
              "      <th>num2</th>\n",
              "      <th>category1_A</th>\n",
              "      <th>category1_B</th>\n",
              "      <th>category1_C</th>\n",
              "      <th>category2_X</th>\n",
              "      <th>category2_Y</th>\n",
              "      <th>category2_Z</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.139401</td>\n",
              "      <td>0.120370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.092131</td>\n",
              "      <td>0.181113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.103859</td>\n",
              "      <td>0.186419</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.100719</td>\n",
              "      <td>0.098470</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.104481</td>\n",
              "      <td>0.121441</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>0.878775</td>\n",
              "      <td>0.886209</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>0.892436</td>\n",
              "      <td>0.879508</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.926543</td>\n",
              "      <td>0.809942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.973000</td>\n",
              "      <td>0.751529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.920492</td>\n",
              "      <td>0.887769</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1894f2f-66fc-45f4-ace2-19c259825b59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1894f2f-66fc-45f4-ace2-19c259825b59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1894f2f-66fc-45f4-ace2-19c259825b59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0f443a50-be3c-4b91-800e-db728d4066d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f443a50-be3c-4b91-800e-db728d4066d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0f443a50-be3c-4b91-800e-db728d4066d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cf74b98f-6d03-4945-aa0a-d32b25ce400a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cf74b98f-6d03-4945-aa0a-d32b25ce400a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 498,\n  \"fields\": [\n    {\n      \"column\": \"num1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3236216340065697,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 498,\n        \"samples\": [\n          0.8665844700571679,\n          0.11156179026714962,\n          0.4863308304658425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3059452975968262,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 498,\n        \"samples\": [\n          0.9759784437715412,\n          0.07833736250628223,\n          0.5053194043612154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category1_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4746445699452991,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category1_B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4674395720746472,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category1_C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47328064594763536,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category2_X\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4759706327913075,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category2_Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.46743957207464726,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category2_Z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47187853249529566,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#------------------------------------------------------------------------------\n",
        "# **Use on your Dataset**\n",
        "\n",
        "### 1. Pre-process (***No missing values*** and any other data cleaning)\n",
        "    - Make sure you've handled MISSING VALUES\n",
        "    - Encoding variables into 0 -> 1 and one-hot encoding are handled by the tarining function\n",
        "\n",
        "### 2. List out columns by variable type (continuous, categorical)  \n",
        "    - List containing the name of the columns with continuous values is defined\n",
        "    - List containing the name of the columns with categorical values is defined  \n",
        "\n",
        "### 3. Set settings for training:  \n",
        "    - data = your cleaned dataset (cannot have missing values)  \n",
        "    - k = number of clusters  \n",
        "    - categorical_cols = The list with the names of the categorical columns  \n",
        "    - numerical_cols = The list with the names of the continuous columns\n",
        "    - batch_size = Defines how many data points are fed into the network per training step\n",
        "\n",
        "### 4. The resulting dataset contains the **TRANSFORMED** variables, and a new column \"Clusters\" containing the cluster assignment for each person."
      ],
      "metadata": {
        "id": "sF8bXqJiEZLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------\n",
        "#------------ Clean your Data ------------\n",
        "#-----------------------------------------\n",
        "#-- Make sure to handle missing values\n",
        "\n",
        "#-----------------------------------------\n",
        "#  List out Columns by variable type\n",
        "#     (numerical, categorical)\n",
        "#-----------------------------------------\n",
        "\n",
        "# numerical_columns = ['age', 'income']\n",
        "# categorical_columns = ['gender', 'subscribed_or_not']\n",
        "\n",
        "\n",
        "#-----------------------------------------\n",
        "#------------ Train the Model ------------\n",
        "#-----------------------------------------\n",
        "results_df = train_model(\n",
        "    #- Pass the name of your dataset\n",
        "    data = dataset_name,\n",
        "    #- Pass the number of clusters\n",
        "    k = number_of_clusters,\n",
        "    #- Pass the lists with the column names\n",
        "    categorical_cols = categorical_columns,\n",
        "    numerical_cols = numerical_columns,\n",
        "    #- Set the batch_size\n",
        "    batch_size = 100)\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------\n",
        "#------------ Resulting Dataframe --------\n",
        "#-----------------------------------------\n",
        "results_df"
      ],
      "metadata": {
        "id": "dOOgjoMHLTvI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
